{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115ac71c",
   "metadata": {},
   "source": [
    "## BLIP-2 Install & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00f808",
   "metadata": {},
   "source": [
    "Scripts working with BLIP-2 image-to-text generation from Salesforce Research.\n",
    "\n",
    "Paper: [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)  \n",
    "Article: [Zero-shot image-to-text generation with BLIP-2](https://huggingface.co/blog/blip-2)  \n",
    "Documentation: [BLIP-2](https://huggingface.co/docs/transformers/main/en/model_doc/blip-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5bee7",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4b4278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1minfo: \u001b[mdownloading component 'rust-std' for 'x86_64-apple-darwin'\n",
      "\u001b[1minfo: \u001b[minstalling component 'rust-std' for 'x86_64-apple-darwin'\n",
      " 24.5 MiB /  24.5 MiB (100 %)  19.0 MiB/s in  1s ETA:  0s\n"
     ]
    }
   ],
   "source": [
    "!rustup target add x86_64-apple-darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9bb08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting safetensors\n",
      "  Using cached safetensors-0.3.2.tar.gz (35 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: safetensors\n",
      "  Building wheel for safetensors (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for safetensors: filename=safetensors-0.3.2-cp39-cp39-macosx_12_0_x86_64.whl size=403925 sha256=effc533704dddfd0c0a7d7ce2171cdfb1184fe587778b4cc6b8299a3d31217a1\n",
      "  Stored in directory: /Users/rachelharrison/Library/Caches/pip/wheels/33/f3/12/beb2fa43480705c919e21e7b9c9bccec1abf7da624d027067e\n",
      "Successfully built safetensors\n",
      "Installing collected packages: safetensors\n",
      "Successfully installed safetensors-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf13efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/01/5sfcrl8n50zb9t8h8tgh_7pw0000gp/T/pip-req-build-fqjzvq49\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/01/5sfcrl8n50zb9t8h8tgh_7pw0000gp/T/pip-req-build-fqjzvq49\n",
      "  Resolved https://github.com/huggingface/transformers to commit 1982dd3b15867c46e1c20645901b0de469fd935f\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.32.0.dev0)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (2022.8.17)\n",
      "Requirement already satisfied: requests in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (0.12.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from transformers==4.32.0.dev0) (4.64.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.0.dev0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.32.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==4.32.0.dev0) (2022.6.15)\n",
      "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.32.0.dev0-py3-none-any.whl size=7522589 sha256=143c39e74d21782398edc06a5d326160d1c0f5c03cfdd9dcff1cfb5db7e8f88a\n",
      "  Stored in directory: /private/var/folders/01/5sfcrl8n50zb9t8h8tgh_7pw0000gp/T/pip-ephem-wheel-cache-mazz0rxg/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: fsspec, huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.8.1\n",
      "    Uninstalling huggingface-hub-0.8.1:\n",
      "      Successfully uninstalled huggingface-hub-0.8.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.1\n",
      "    Uninstalling transformers-4.21.1:\n",
      "      Successfully uninstalled transformers-4.21.1\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 transformers-4.32.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0afe9ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/70/f9/c381bcdd0c3829d723aa14eec8e75c6c377b4ca61ec68b8093d9f35fc7a7/accelerate-0.21.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from accelerate) (1.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/rachelharrison/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.3.0)\n",
      "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e1e35",
   "metadata": {},
   "source": [
    "### BLIP-2, OPT-2.7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab3bdcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c668ae4dc9416285ea92d05659a298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model setup: OPT-2.7b\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float32\n",
    ")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62e89135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman in a straw hat picking apples from an orchard\n"
     ]
    }
   ],
   "source": [
    "# Image captioning (without providing a text prompt):\n",
    "\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "image = Image.open('./wain23_images_v2/pexels-zen-chung-5529541.jpg')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(device, torch.float16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=64, temperature=0)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e4f11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Visual question answering (prompt = question):\n",
    "\n",
    "image = Image.open('./wain23_images_v2/pexels-zen-chung-5529541.jpg')\n",
    "\n",
    "prompt = \"How many people are in this image?\"\n",
    "inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=40)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "726a1fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing complex QA prompt:\n",
    "\n",
    "image = Image.open('./wain23_images_v2/pexels-zen-chung-5529541.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as alt text, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? Answer:\"\n",
    "\n",
    "inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=124)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9bf078bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate alt text consisting of no more than one sentence for the following image that briefly describes the activity shown as well as the approximate gender, age, and race of the person in the image (if possible). The age categories are: young adult, adult, middle aged, senior.'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Generate alt text consisting of no more than one sentence for the following image that briefly \\\n",
    "describes the activity shown as well as the approximate gender, age, and race of the person in the image \\\n",
    "(if possible). The age categories are: young adult, adult, middle aged, senior.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094b8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa888b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0c090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34eb1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7e36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3924097e",
   "metadata": {},
   "source": [
    "### BLIP-2, Flan T5-xxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd94331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d7bd66cbfc4b2e97ae7a88dd50a7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b448c35f4549e0ba3cd9497448cfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffa91eabc444902b92017e7bac1545b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bf6e6bf3504f3d8c4f9c6dad271cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8de79bbea2343d3a590586170c86b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c86cc76434f430bb1b6658931698a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/6.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d2ea15b4a14644b5b84d00f0dbcc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/128k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d936f96299c348bf8a78b68a6af0763f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9932d8e128b4104ad1aca1ab403ac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00006.bin:   0%|          | 0.00/9.37G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b31eb7b267b49d195463370901bdc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00006.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0bd2b95c944fe9844a22f058fcd2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00006.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62825dd6f697476aae8aa8f64e85cecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00006.bin:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0253d2d92b4a2798e5a4a9eccee408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00006.bin:   0%|          | 0.00/9.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688b49a00c154906ba2d17328a894497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00006-of-00006.bin:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903ad11686684aafaaf4b4d22d9d9abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model setup: Flan T5-xxl\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor2 = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xxl\")\n",
    "model2 = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip2-flan-t5-xxl\", torch_dtype=torch.float32\n",
    ")\n",
    "model2.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da5377e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senior black woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "# VQA Testing\n",
    "\n",
    "image = Image.open('./wain23_images_v2/pexels-zen-chung-5529541.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as alt text, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race (white, black, asian, hispanic) of the person in the photo, and what activity are they engaging in? Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f1f8cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman, middle aged, white, working at home, writing\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-andrea-piacquadio-3768176.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as alt text, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race (white, black, asian, hispanic) of the person in the photo, and what activity are they engaging in? Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abf96896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a white notebook, a cup of coffee, and a pen on a white table\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-madison-inouye-2180092.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9c19ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man is planting a seed in the ground in a garden\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-binyamin-mellish-169523.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a647821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young african american woman listening to music with headphones on an orange background\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-orione-conceição-8663203.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d538be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman writing on a paper with a glass of wine\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-karolina-grabowska-4467583.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6894ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asian man preparing a dish in a kitchen\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-ono-kosuki-5973906.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbe25c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman cleaning the mirror with rubber gloves and rags in the bathroom\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('./wain23_images_v2/pexels-shvets-production-7513038.jpg')\n",
    "\n",
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "\n",
    "inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "\n",
    "generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecce6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29eb1ede",
   "metadata": {},
   "source": [
    "def create_caption(prompt, image):\n",
    "    inputs = processor2(image, text=prompt, return_tensors=\"pt\").to(device, torch.float32)\n",
    "    \n",
    "    generated_ids = model2.generate(**inputs, min_new_tokens=12, max_new_tokens=128, temperature=0)\n",
    "    generated_text = processor2.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "25739a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young adult, adult, \\\n",
    "middle aged, senior), and what activity are they engaging in? Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "783c991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman, middle aged, white, writing, working at home\n",
      "pexels-zen-chung-5529541.jpg: senior, black, female, picking apples in an orchard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir = './wain23_images_v3/'\n",
    "for image_name in sorted(os.listdir(image_dir)):\n",
    "    image = Image.open(image_dir + image_name)\n",
    "    caption = create_caption(prompt, image)\n",
    "    print(f'{image_name}: {caption}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65332985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "022832c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_images(prompt, image_dir='./wain23_images_v3/'):\n",
    "    for image_name in sorted(os.listdir(image_dir)):\n",
    "        if image_name == '.DS_Store':\n",
    "            continue\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        caption = create_caption(prompt, image)\n",
    "        print(f'{image_name}: {caption}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young adult, adult, middle aged, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\\n",
    "If there is no person, simply describe the image. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Question: If the image contains a person, what is their gender, age (young adult, adult, \\\n",
    "middle aged, senior), and race, and what activity are they engaging in? \\ If there is no person, \\\n",
    "simply describe the image. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d534ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Question: What would be good alt text for this image? If the image contains a person, \\\n",
    "describe their gender, age (young adult, adult, senior), and race. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d8e060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman, middle aged, white, writing, working at home\n",
      "pexels-zen-chung-5529541.jpg: senior, black, female, picking apples in an orchard\n"
     ]
    }
   ],
   "source": [
    "# Current Best - remove \"middle aged\"\n",
    "\n",
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young adult, adult, \\\n",
    "middle aged, senior), and what activity are they engaging in? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "309c649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman in glasses writing at home on a laptop stock photo\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young adult, adult, \\\n",
    "senior), and what activity are they engaging in? Format your answer as an alt text caption. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "79b0678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman in glasses sitting at a desk writing on a piece of paper\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Formatted as alt text, if the photo contains a person, what is their gender, race, \\\n",
    "and age (young adult, adult, senior), and what activity are they engaging in? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0923d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman, white, age, adult, activity, writing, work\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young adult, adult, \\\n",
    "senior), and what activity are they engaging in? If the photo does not contain a person, what is the photo \\\n",
    "of? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ed07a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman in glasses sitting at a desk writing on a piece of paper\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fb013\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young adult, adult, \\\n",
    "senior), and what are they doing? If the photo does not contain a person, what is the photo of? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ead53453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman in glasses sitting at a desk writing on a piece of paper\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fb015\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: What is this a photo of? If the photo contains a person, what is their gender, race, \\\n",
    "and age (young adult, adult, senior), and what are they doing? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "effce7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: a woman working at home on her laptop, writing a letter\n",
      "pexels-zen-chung-5529541.jpg: an older woman picking apples in an orchard - fb015\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If an image contais a person, the caption should identify their gender, race, \\\n",
    "age (young adult, adult, senior), and what they are doing. This is an image of\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ecc65bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen on paper - stock photo\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard - fb\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: What is a good caption for this photo? If it contais a person, the caption should \\\n",
    "identify their gender, race, age (young adult, adult, senior), and what they are doing. What is a \\\n",
    "good caption? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8721b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman, middle aged, white, writing, working at home\n",
      "pexels-madison-inouye-2180092.jpg: young adult, white, adult, middle aged, senior, writing\n",
      "pexels-zen-chung-5529541.jpg: senior, black, female, picking apples in an orchard\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young adult, adult, \\\n",
    "middle aged, senior), and what activity are they engaging in? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7ca1cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen in hand - stock photo\n",
      "pexels-madison-inouye-2180092.jpg: young adult, white, adult, writing in a journal\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fb015\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Caption the photo. If the photo contains a person, what is their gender, race, and \\\n",
    "age (young adult, adult, senior), and what activity are they engaging in? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "13358cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen on paper - stock photo\n",
      "pexels-madison-inouye-2180092.jpg: a notebook, a cup of coffee, and a pen\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Caption the photo, and if the photo contains a person, list their gender, race, and \\\n",
    "age (young, adult, senior), and what they are doing. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14cb07c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen on a table\n",
      "pexels-madison-inouye-2180092.jpg: a young woman is writing in her journal and drinking a cup of coffee\n",
      "pexels-zen-chung-5529541.jpg: a woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Caption the photo, and if the photo contains a person, list their gender, race, and \\\n",
    "age (young, adult, senior), and what they are doing. A good caption with all required attributes is\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e94a305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: young black woman reading a book at home in front of a window\n",
      "pexels-madison-inouye-2180092.jpg: young black woman reading a book on a white surface\n",
      "pexels-zen-chung-5529541.jpg: young black woman reading a book in the park - fb\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Caption the photo, and if the photo contains a person, list their gender, race, and \\\n",
    "age (young, adult, senior), and what they are doing. Example: A young black woman reading a book. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "46586655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen in hand - stock photo\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, pens, and a book\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Formatted as an alt text caption, what is the gender, age (young, adult, senior), \\\n",
    "and race of the person in the photo, and what activity are they engaging in? \\ If there is no person, \\\n",
    "simply describe the image. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b44afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman, white, adult, writing, working at home, home office\n",
      "pexels-pixabay-159618.jpg: young, adult, senior, writing in a book,\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: If the photo contains a person, what is their gender, race, and age (young, adult, \\\n",
    "senior), and what activity are they engaging in? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aa96c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen on paper - stock photo\n",
      "pexels-pixabay-159618.jpg: a desk with a clock, pencils, and a book\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Caption the photo, and if the photo contains a person, mention their gender, race, \\\n",
    "age (young, adult, senior), and what they are doing. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ac414862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman sitting at a table writing on a piece of paper\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, pens, and a book\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard - fb013\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: What is the gender, age (young, adult, senior), and race of the person in the photo, \\\n",
    "and what activity are they engaging in? If there is no person, simply describe the image. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0e53b63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen in the living room\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, and a book\n",
      "pexels-zen-chung-5529541.jpg: senior woman picking apples in orchard - fb015\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Generate alt text consisting of no more than one sentence for the following image that briefly \\\n",
    "describes the activity shown as well as the approximate gender, age, and race of the person in the image \\\n",
    "(if possible). The age categories are: young, adult, and senior. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0bcaf0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen on paper - stock photo\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, and a book\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: You are tasked with generating alt text. Alt text must describe the activity shown \\\n",
    "as well as the approximate gender, age, and race of the person in the image (if possible). The age \\\n",
    "categories are: young, adult, and senior. If there is no person in the image, describe the image. Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "62a1fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: a woman is working at home on her laptop and writing\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, pens, and a notebook\n",
      "pexels-zen-chung-5529541.jpg: a senior woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Good alt text contains all information about an image, including all the attributes of people in \\\n",
    "the image. Attributes are gender, age (young, adult, senior), and race. Good alt text for this image would be\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b2b71075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: a woman is working at home on her laptop and writing\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, and a notebook\n",
      "pexels-zen-chung-5529541.jpg: a woman picking apples in an orchard - fbf018\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Alt text that thoroughly describes the person in this image (including gender, age, and race \\\n",
    "attributes) would be\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1057f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman working at home with laptop and pen in hand - stock photo\n",
      "pexels-pixabay-159618.jpg: A desk with a clock, pencils, pens, and a notebook\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard - fb\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: What is a thorough and detailed caption for this image? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8595728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman in glasses sitting at a table writing on a piece of paper\n",
      "pexels-toa-heftiba-şinca-1194408.jpg: male, young, adult, white, reading a book in the dead sea\n",
      "pexels-zen-chung-5529541.jpg: woman, age adult, race african american, picking apples in an orchard\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Formatted as a sentence, what is the gender, age (young, adult, senior), and race of \\\n",
    "the person in this photo, and what are they doing? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "41dd0e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman in glasses writing at home with laptop and pen stock photo\n",
      "pexels-toa-heftiba-şinca-1194408.jpg: reading a book in the dead sea, israel, male, young, adult, israeli\n",
      "pexels-zen-chung-5529541.jpg: woman picking apples in an orchard, age adult, race african american\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: Formatted as a sentence, what is the person in this photo doing and what is their \\\n",
    "gender, age (young, adult, senior), and race? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "feb7ac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman writing at home, white, adult, senior, blond hair\n",
      "pexels-toa-heftiba-şinca-1194408.jpg: reading a book in the dead sea, israel, male, young, adult, israeli\n",
      "pexels-zen-chung-5529541.jpg: picking apples in an orchard, female, adult, black\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: What is the person in this photo doing and what is their gender, age (young, adult, senior), \\\n",
    "and race? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a05ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3768176.jpg: woman, adult, white, sitting at a desk, writing\n",
      "pexels-toa-heftiba-şinca-1194408.jpg: male, young, adult, israeli, reading a book in the dead sea\n",
      "pexels-zen-chung-5529541.jpg: senior, black, female, picking apples in an orchard\n"
     ]
    }
   ],
   "source": [
    "# Person-only working prompt\n",
    "\n",
    "prompt = \"Question: What is the gender, age (young, adult, senior), and race of the person in this photo, \\\n",
    "and what are they doing? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ed0ac001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-akshar-dave-977971.jpg: male, young, indian, playing guitar, smiling, sitting on the floor\n",
      "pexels-alena-koval-820673.jpg: female, adult, white, drawing a doodle\n",
      "pexels-andrea-piacquadio-3768176.jpg: woman, adult, white, sitting at a desk, writing\n",
      "pexels-andrea-piacquadio-3769999.jpg: woman, adult, white, preparing food, smiling, preparing food\n",
      "pexels-andrea-piacquadio-3782829.jpg: senior, white, male, glasses, reading, walking, outdoors\n",
      "pexels-beyzaa-yurtkuran-13533591.jpg: male, adult, white, reading a newspaper, crossword puzzle\n",
      "pexels-binyamin-mellish-169523.jpg: male, adult, white, and they are planting a seed\n",
      "pexels-cottonbro-studio-4004116.jpg: female, adult, and asian, and they are putting clothes on a hanger\n",
      "pexels-cottonbro-studio-4045621.jpg: reading a newspaper in bed, afro-american, adult\n",
      "pexels-cottonbro-studio-7885580.jpg: senior, white, male, painting, painting a flower\n",
      "pexels-italo-melo-1786244.jpg: senior, female, asian, and dancing in the street\n",
      "pexels-jackson-david-2810210.jpg: female, adult, white, making a heart with their hands\n",
      "pexels-kampus-production-6838581.jpg: senior, male, white, playing cards with his wife in the park\n",
      "pexels-karolina-grabowska-4467583.jpg: woman, adult, white, writing on a piece of paper\n",
      "pexels-kelvin-valerio-810775.jpg: young, adult, and latino, and they are looking up\n",
      "pexels-king-siberia-2547907.jpg: female, young, asian, looking at the sky\n",
      "pexels-mental-health-america-(mha)-5531323.jpg: female, adult, asian, reading a book\n",
      "pexels-meruyert-gonullu-8290102.jpg: woman, red hair, adult, white, putting dishes in the kitchen cupboard\n",
      "pexels-nappy-3536630.jpg: male, young, black, reading to a baby, sitting\n",
      "pexels-ono-kosuki-5973906.jpg: male, adult, asian, making a sandwich\n",
      "pexels-orione-conceição-8663203.jpg: young black woman with headphones listening to music on an orange background\n",
      "pexels-pixabay-159579.jpg: young, female, white, and they are coloring with crayons\n",
      "pexels-prathsnap-4017663.jpg: playing cards with a white person, adult, white, playing cards\n",
      "pexels-shu-lei-13865878.jpg: female, asian, adult, meditating\n",
      "pexels-shvets-production-7513038.jpg: female, young, adult, white, cleaning the mirror with gloves\n",
      "pexels-shvets-production-8417223.jpg: senior woman in a floral dress walking with a basket on her bike\n",
      "pexels-thijs-van-der-weide-1094767.jpg: male, adult, white, and they are working on a wooden piece\n",
      "pexels-tima-miroshnichenko-5390111.jpg: female, adult, white, and they are petting a dog\n",
      "pexels-toa-heftiba-şinca-1194408.jpg: male, young, adult, israeli, reading a book in the dead sea\n",
      "pexels-vlada-karpovich-5603003.jpg: female, adult, white, knitting, sitting on couch, holding yarn\n",
      "pexels-zen-chung-5529541.jpg: senior, black, female, picking apples in an orchard\n",
      "pexels-zen-chung-5749775.jpg: male, adult, black, walking a dog in the woods\n"
     ]
    }
   ],
   "source": [
    "# using wain23_images_v3_init\n",
    "\n",
    "prompt = \"Question: What is the gender, age (young, adult, senior), and race of the person in this photo, \\\n",
    "and what are they doing? Answer:\"\n",
    "caption_images(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d042d28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pexels-andrea-piacquadio-3967832.jpg: female, young, adult, and smiling while leaning on the edge of a swimming pool\n",
      "pexels-antoni-shkraba-production-8791162.jpg: senior man with beard playing with wooden blocks in the living room\n",
      "pexels-budgeron-bach-5157742.jpg: young black man holding a skateboard in the street, posing for a photo\n",
      "pexels-cottonbro-studio-9710643.jpg: male, young, black, watering plants in a kitchen\n",
      "pexels-eli-zaturanski-821683.jpg: male, adult, white, drawing a mountain landscape on a piece of paper\n",
      "pexels-jeshootscom-7432.jpg: female, young, adult, and asian, and they are tying their shoes\n",
      "pexels-ketut-subiyanto-4132326.jpg: writing in a journal, white, adult, and writing\n",
      "pexels-ketut-subiyanto-5038856.jpg: young, male, indian, tying shoelaces\n",
      "pexels-ketut-subiyanto-5039638.jpg: young, black, female, sitting on stairs, tying shoes\n",
      "pexels-mikhail-nilov-6620627.jpg: female, adult, white, aiming at a bow and arrow\n",
      "pexels-nappy-936037.jpg: a young person, white, is playing basketball outdoors in a park\n",
      "pexels-pavel-danilyuk-7119094.jpg: male, adult, white, writing on paper at a table\n",
      "pexels-pixabay-39854.jpg: male, adult, white, fishing, holding a fishing rod\n",
      "pexels-rdne-stock-project-6657657.jpg: male, adult, black, writing on a notepad\n",
      "pexels-rfstudio-3817500.jpg: woman, adult, afro-american, painting a bowl\n",
      "pexels-rocketmann-team-9507233.jpg: woman, asian, adult, watering a plant\n",
      "pexels-ron-lach-7883466.jpg: senior, female, white, sitting on the floor, drawing\n",
      "pexels-sam-lion-6001197.jpg: woman, adult, curly hair, white, sitting on the couch, petting a cat\n",
      "pexels-sam-lion-6001202.jpg: woman, adult, white, holding a cat, sitting on the floor\n",
      "pexels-shvets-production-7516537.jpg: female, young, white, writing in a notebook, studying\n",
      "pexels-vlada-karpovich-6114964.jpg: woman, young, adult, white, playing chess\n",
      "pexels-yan-krukau-6611307.jpg: male, adult, white, and they are making a vase\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Question: What is the gender, age (young, adult, senior), and race of the person in this photo, \\\n",
    "and what are they doing? Answer:\"\n",
    "caption_images(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
